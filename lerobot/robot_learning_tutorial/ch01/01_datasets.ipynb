{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a3d28a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 设置 HuggingFace 镜像和缓存路径\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "os.environ[\"HF_HOME\"]  = \"/zhouzhili/liber\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c675af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from lerobot.datasets.lerobot_dataset import LeRobotDataset\n",
    "from lerobot.datasets.streaming_dataset import StreamingLeRobotDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac73500f",
   "metadata": {},
   "source": [
    "### delta_timestamps\n",
    "\n",
    "1. 定义：delta_timestamps 用来为指定键取一段时间窗口的帧（过去/当前/未来），单位秒；会把样本从“单帧”变成“时间序列”（增加时间维度 T），并在越界时提供掩码，便于时序建模。\n",
    "2. 为某些键指定“相对当前帧的时间偏移”（单位=秒）。负数=过去，0=当前，正数=未来。\n",
    "3. 作用：让每个样本自带一段时间窗口的数据，给模型提供时序上下文（例如看过去几帧的图像/状态，以便预测当前或未来的动作）\n",
    "4. 对张量形状的影响\n",
    "* 不设置时：键的张量是常规形状，如图像为 (C, H, W)。\n",
    "* 设置后：会在最前面多一个时间维度 T，如图像为 (T, C, H, W)，T 等于你给的偏移数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37d23616",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_timestamps = {\n",
    "    \"observation.images.up\": [-0.2, -0.1, 0.0] \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c06768",
   "metadata": {},
   "source": [
    "## Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61a61f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LeRobotDataset(\n",
    "    repo_id=\"lerobot/svla_so101_pickplace\",\n",
    "    delta_timestamps=delta_timestamps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d0493e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# fps\n",
    "print(dataset.fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "426b99ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取数据集中的第 100 帧\n",
    "sample = dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa77d156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "keys: ['observation.images.up', 'observation.images.side', 'action', 'observation.state', 'timestamp', 'frame_index', 'episode_index', 'index', 'task_index', 'observation.images.up_is_pad', 'task']\n",
      "observation.images.up                     type=Tensor  shape=torch.Size([3, 3, 480, 640])\n",
      "observation.images.side                   type=Tensor  shape=torch.Size([3, 480, 640])\n",
      "action                                    type=Tensor  shape=torch.Size([6])\n",
      "observation.state                         type=Tensor  shape=torch.Size([6])\n",
      "timestamp                                 type=Tensor  shape=torch.Size([])\n",
      "frame_index                               type=Tensor  shape=torch.Size([])\n",
      "episode_index                             type=Tensor  shape=torch.Size([])\n",
      "index                                     type=Tensor  shape=torch.Size([])\n",
      "task_index                                type=Tensor  shape=torch.Size([])\n",
      "observation.images.up_is_pad              type=Tensor  shape=torch.Size([3])\n",
      "task                                      type=str  shape=None\n"
     ]
    }
   ],
   "source": [
    "print(type(sample))\n",
    "print(\"keys:\", list(sample.keys()))\n",
    "\n",
    "for k, v in sample.items():\n",
    "    shape = getattr(v, \"shape\", None)\n",
    "    print(f\"{k:40s}  type={type(v).__name__}  shape={shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b576f082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'observation.images.up': tensor([[[[0.4941, 0.4941, 0.4941,  ..., 0.6745, 0.6745, 0.6745],\n",
      "          [0.4980, 0.4980, 0.4980,  ..., 0.6745, 0.6745, 0.6745],\n",
      "          [0.5098, 0.5098, 0.5098,  ..., 0.6745, 0.6745, 0.6745],\n",
      "          ...,\n",
      "          [0.6039, 0.6039, 0.6039,  ..., 0.5216, 0.5216, 0.5216],\n",
      "          [0.6039, 0.6039, 0.6039,  ..., 0.5216, 0.5216, 0.5216],\n",
      "          [0.6039, 0.6039, 0.6039,  ..., 0.5216, 0.5216, 0.5216]],\n",
      "\n",
      "         [[0.5176, 0.5176, 0.5176,  ..., 0.6824, 0.6824, 0.6824],\n",
      "          [0.5216, 0.5216, 0.5216,  ..., 0.6824, 0.6824, 0.6824],\n",
      "          [0.5333, 0.5333, 0.5333,  ..., 0.6824, 0.6824, 0.6824],\n",
      "          ...,\n",
      "          [0.6196, 0.6196, 0.6196,  ..., 0.5216, 0.5216, 0.5216],\n",
      "          [0.6196, 0.6196, 0.6196,  ..., 0.5216, 0.5216, 0.5216],\n",
      "          [0.6196, 0.6196, 0.6196,  ..., 0.5216, 0.5216, 0.5216]],\n",
      "\n",
      "         [[0.5216, 0.5216, 0.5216,  ..., 0.6824, 0.6824, 0.6824],\n",
      "          [0.5255, 0.5255, 0.5255,  ..., 0.6824, 0.6824, 0.6824],\n",
      "          [0.5373, 0.5373, 0.5373,  ..., 0.6824, 0.6824, 0.6824],\n",
      "          ...,\n",
      "          [0.6353, 0.6353, 0.6353,  ..., 0.5216, 0.5216, 0.5216],\n",
      "          [0.6353, 0.6353, 0.6353,  ..., 0.5216, 0.5216, 0.5216],\n",
      "          [0.6353, 0.6353, 0.6353,  ..., 0.5216, 0.5216, 0.5216]]],\n",
      "\n",
      "\n",
      "        [[[0.5059, 0.5059, 0.5059,  ..., 0.6824, 0.6824, 0.6824],\n",
      "          [0.5137, 0.5137, 0.5137,  ..., 0.6824, 0.6824, 0.6824],\n",
      "          [0.5255, 0.5255, 0.5255,  ..., 0.6824, 0.6824, 0.6824],\n",
      "          ...,\n",
      "          [0.6118, 0.6118, 0.6118,  ..., 0.5137, 0.5137, 0.5137],\n",
      "          [0.6118, 0.6118, 0.6118,  ..., 0.5137, 0.5137, 0.5137],\n",
      "          [0.6118, 0.6118, 0.6118,  ..., 0.5137, 0.5137, 0.5137]],\n",
      "\n",
      "         [[0.5098, 0.5098, 0.5098,  ..., 0.6824, 0.6824, 0.6824],\n",
      "          [0.5176, 0.5176, 0.5176,  ..., 0.6824, 0.6824, 0.6824],\n",
      "          [0.5294, 0.5294, 0.5294,  ..., 0.6824, 0.6824, 0.6824],\n",
      "          ...,\n",
      "          [0.6157, 0.6157, 0.6157,  ..., 0.5216, 0.5216, 0.5216],\n",
      "          [0.6157, 0.6157, 0.6157,  ..., 0.5216, 0.5216, 0.5216],\n",
      "          [0.6157, 0.6157, 0.6157,  ..., 0.5216, 0.5216, 0.5216]],\n",
      "\n",
      "         [[0.5216, 0.5216, 0.5216,  ..., 0.6824, 0.6824, 0.6824],\n",
      "          [0.5294, 0.5294, 0.5294,  ..., 0.6824, 0.6824, 0.6824],\n",
      "          [0.5412, 0.5412, 0.5412,  ..., 0.6824, 0.6824, 0.6824],\n",
      "          ...,\n",
      "          [0.6353, 0.6353, 0.6353,  ..., 0.5216, 0.5216, 0.5216],\n",
      "          [0.6353, 0.6353, 0.6353,  ..., 0.5216, 0.5216, 0.5216],\n",
      "          [0.6353, 0.6353, 0.6353,  ..., 0.5216, 0.5216, 0.5216]]],\n",
      "\n",
      "\n",
      "        [[[0.4863, 0.4902, 0.4902,  ..., 0.6706, 0.6706, 0.6706],\n",
      "          [0.4980, 0.4980, 0.4980,  ..., 0.6706, 0.6745, 0.6745],\n",
      "          [0.5098, 0.5098, 0.5098,  ..., 0.6745, 0.6745, 0.6745],\n",
      "          ...,\n",
      "          [0.6039, 0.6039, 0.6039,  ..., 0.5176, 0.5176, 0.5176],\n",
      "          [0.6039, 0.6039, 0.6039,  ..., 0.5176, 0.5176, 0.5176],\n",
      "          [0.6039, 0.6039, 0.6039,  ..., 0.5176, 0.5176, 0.5176]],\n",
      "\n",
      "         [[0.5059, 0.5098, 0.5098,  ..., 0.6784, 0.6784, 0.6784],\n",
      "          [0.5176, 0.5176, 0.5176,  ..., 0.6784, 0.6824, 0.6824],\n",
      "          [0.5373, 0.5373, 0.5373,  ..., 0.6824, 0.6824, 0.6824],\n",
      "          ...,\n",
      "          [0.6196, 0.6196, 0.6196,  ..., 0.5176, 0.5176, 0.5176],\n",
      "          [0.6196, 0.6196, 0.6196,  ..., 0.5176, 0.5176, 0.5176],\n",
      "          [0.6196, 0.6196, 0.6196,  ..., 0.5176, 0.5176, 0.5176]],\n",
      "\n",
      "         [[0.5020, 0.5059, 0.5059,  ..., 0.6784, 0.6784, 0.6784],\n",
      "          [0.5137, 0.5137, 0.5137,  ..., 0.6784, 0.6824, 0.6824],\n",
      "          [0.5294, 0.5294, 0.5294,  ..., 0.6824, 0.6824, 0.6824],\n",
      "          ...,\n",
      "          [0.6275, 0.6275, 0.6275,  ..., 0.5176, 0.5176, 0.5176],\n",
      "          [0.6275, 0.6275, 0.6275,  ..., 0.5176, 0.5176, 0.5176],\n",
      "          [0.6275, 0.6275, 0.6275,  ..., 0.5176, 0.5176, 0.5176]]]]), 'observation.images.side': tensor([[[0.5137, 0.5137, 0.5137,  ..., 0.3098, 0.3098, 0.3098],\n",
      "         [0.5137, 0.5137, 0.5137,  ..., 0.3098, 0.3098, 0.3098],\n",
      "         [0.5137, 0.5137, 0.5137,  ..., 0.3059, 0.3059, 0.3059],\n",
      "         ...,\n",
      "         [0.5647, 0.5647, 0.5647,  ..., 0.6039, 0.6039, 0.6039],\n",
      "         [0.5647, 0.5647, 0.5647,  ..., 0.6039, 0.6039, 0.6039],\n",
      "         [0.5647, 0.5647, 0.5647,  ..., 0.6039, 0.6039, 0.6039]],\n",
      "\n",
      "        [[0.5216, 0.5216, 0.5216,  ..., 0.2549, 0.2549, 0.2549],\n",
      "         [0.5216, 0.5216, 0.5216,  ..., 0.2549, 0.2549, 0.2549],\n",
      "         [0.5216, 0.5216, 0.5216,  ..., 0.2510, 0.2510, 0.2510],\n",
      "         ...,\n",
      "         [0.5647, 0.5647, 0.5647,  ..., 0.6078, 0.6078, 0.6078],\n",
      "         [0.5647, 0.5647, 0.5647,  ..., 0.6078, 0.6078, 0.6078],\n",
      "         [0.5647, 0.5647, 0.5647,  ..., 0.6078, 0.6078, 0.6078]],\n",
      "\n",
      "        [[0.5216, 0.5216, 0.5216,  ..., 0.2000, 0.2000, 0.2000],\n",
      "         [0.5216, 0.5216, 0.5216,  ..., 0.2000, 0.2000, 0.2000],\n",
      "         [0.5216, 0.5216, 0.5216,  ..., 0.1961, 0.1961, 0.1961],\n",
      "         ...,\n",
      "         [0.5647, 0.5647, 0.5647,  ..., 0.6196, 0.6196, 0.6196],\n",
      "         [0.5647, 0.5647, 0.5647,  ..., 0.6196, 0.6196, 0.6196],\n",
      "         [0.5647, 0.5647, 0.5647,  ..., 0.6196, 0.6196, 0.6196]]]), 'action': tensor([  9.4853, -78.4421,  69.0487,  74.4156, -48.4737,  13.6785]), 'observation.state': tensor([  7.0659, -98.1575,  85.2981,  74.9046, -48.6203,   3.2886]), 'timestamp': tensor(3.3333), 'frame_index': tensor(100), 'episode_index': tensor(0), 'index': tensor(100), 'task_index': tensor(0), 'observation.images.up_is_pad': tensor([False, False, False]), 'task': 'pink lego brick into the transparent box'}\n"
     ]
    }
   ],
   "source": [
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2588adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "# 将数据集包装在 DataLoader 中，以便将其批量处理用于训练目的\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea860e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在训练循环中迭代 DataLoader\n",
    "num_epochs = 1\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in data_loader:\n",
    "        # 移动数据到适当的设备（例如 GPU）\n",
    "        observations = batch[\"observation.state\"].to(device)\n",
    "        actions = batch[\"action\"].to(device)\n",
    "        \n",
    "        # model.forward(batch)\n",
    "        print(f\"batch keys: {batch.keys()}\")\n",
    "        print(f\"observations: {observations.shape}\")\n",
    "        print(f\"actions: {actions.shape}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c05b07b",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdd32725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 StreamingLeRobotDataset 来避免下载数据集\n",
    "# 从 Hugging Face Hub 流式传输帧，无需加载到内存中\n",
    "streaming_dataset = StreamingLeRobotDataset(\n",
    "    \"lerobot/svla_so101_pickplace\",\n",
    "    delta_timestamps=delta_timestamps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "431b7c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# fps\n",
    "print(streaming_dataset.fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "faf65b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "streaming_dataset keys: dict_keys(['action', 'observation.state', 'timestamp', 'frame_index', 'episode_index', 'index', 'task_index', 'observation.images.up', 'observation.images.side', 'observation.images.up_is_pad', 'task'])\n"
     ]
    }
   ],
   "source": [
    "streaming_sample = next(iter(streaming_dataset))\n",
    "print(f\"streaming_dataset keys: {streaming_sample.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1afde8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 480, 640])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming_img = streaming_sample[\"observation.images.up\"]\n",
    "streaming_img.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robot_learning_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
